{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "#https://www.tensorflow.org/tutorials/keras/regression\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Menu Item Number</th>\n",
       "      <th>Menu Item</th>\n",
       "      <th>Sales Count</th>\n",
       "      <th>Sales Total</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Name of Restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2429</td>\n",
       "      <td>TO GO</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>Origami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>3624</td>\n",
       "      <td>SALMON POKE BOWL</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>Origami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>3630</td>\n",
       "      <td>SPCY CRAB MAKI</td>\n",
       "      <td>17</td>\n",
       "      <td>114.75</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>Origami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3631</td>\n",
       "      <td>SALM CR CHZ MAKI</td>\n",
       "      <td>8</td>\n",
       "      <td>55.6</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>Origami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>3632</td>\n",
       "      <td>TUNA MAKI</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>Origami</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idx Menu Item Number         Menu Item Sales Count Sales Total        Date  \\\n",
       "0   7             2429             TO GO           1           0  2019-03-18   \n",
       "1   8             3624  SALMON POKE BOWL           4          29  2019-03-18   \n",
       "2   9             3630    SPCY CRAB MAKI          17      114.75  2019-03-18   \n",
       "3  10             3631  SALM CR CHZ MAKI           8        55.6  2019-03-18   \n",
       "4  11             3632         TUNA MAKI           2        13.5  2019-03-18   \n",
       "\n",
       "  Day Name of Restaurant  \n",
       "0   0            Origami  \n",
       "1   0            Origami  \n",
       "2   0            Origami  \n",
       "3   0            Origami  \n",
       "4   0            Origami  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path=\"merged.csv\"\n",
    "column_names = ['idx','Menu Item Number','Menu Item','Sales Count','Sales Total', \n",
    "                'Date', 'Day', 'Name of Restaurant']\n",
    "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
    "                      na_values = \"?\",dtype={'idx': object},\n",
    "                      sep=\",\", skiprows=[0])\n",
    "raw_dataset.drop(['idx'], axis=1)\n",
    "dataset = raw_dataset.copy()\n",
    "#find unknown values\n",
    "dataset.isna().sum()\n",
    "#drop rows with unknown values\n",
    "dataset = dataset.dropna()\n",
    "#dataset.tail(30)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useless idx col\n",
    "dataset.pop('idx')\n",
    "#manually clean errors in dataset :(\n",
    "#day column is string, convert it to int \n",
    "dataset['Sales Count'] = dataset['Sales Count'].astype(int)\n",
    "dataset['Sales Total'] = dataset['Sales Total'].astype(float) #encountered '$-' in csv 115610, manually changed to 0\n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
    "dataset['Day'] = dataset['Day'].astype(int)\n",
    "\n",
    "#Day column is categorical not numeric\n",
    "day = dataset.pop('Day')\n",
    "# print(day.dtypes)\n",
    "dataset['Mon'] = (day == 0)*1.0\n",
    "dataset['Tues'] = (day == 1)*1.0\n",
    "dataset['Wed'] = (day == 2)*1.0\n",
    "dataset['Thurs'] = (day == 3)*1.0\n",
    "dataset['Fri'] = (day == 4)*1.0\n",
    "dataset['Sat'] = (day == 5)*1.0\n",
    "dataset['Sun'] = (day == 6)*1.0\n",
    "\n",
    "dataset['Year'] = pd.DatetimeIndex(dataset['Date']).year\n",
    "dataset['Month'] = pd.DatetimeIndex(dataset['Date']).month\n",
    "dataset.head()\n",
    "df = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1105 02:18:38.258245 140309402412864 deprecation.py:506] From /home/punishment/Projects/dining_services/env/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n",
      "Epoch 1/5000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8e5f7d33062e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#Fit model to training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training completed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/dining_services/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Projects/dining_services/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/dining_services/env/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m         \u001b[0mtensor_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m         array_vals.append(np.asarray(value,\n\u001b[0;32m-> 3130\u001b[0;31m                                      dtype=tensor_type.as_numpy_dtype))\n\u001b[0m\u001b[1;32m   3131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/dining_services/env/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "dates = df.index\n",
    "#Split targets and features\n",
    "X = df.iloc[:,4:14]\n",
    "Y = df.iloc[:,2]\n",
    "\n",
    "\n",
    "#Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, shuffle=True)\n",
    "\n",
    "#Count features for modelization\n",
    "X_num_columns= len(X.columns)\n",
    "\n",
    "#Define model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(300,\n",
    "                activation='relu',\n",
    "                input_dim = X_num_columns))\n",
    "\n",
    "model.add(layers.Dense(90,\n",
    "                activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(30,\n",
    "                activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(7,\n",
    "                activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(1,\n",
    "                activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "print(\"Model Created\")\n",
    "\n",
    "#Fit model to training data\n",
    "model.fit(X_train, y_train, epochs=5000, batch_size=100)\n",
    "print(\"Training completed\")\n",
    "\n",
    "#Save trained model\n",
    "model.save(\"Sales_model.h5\")\n",
    "print(\"Sales_model.h5 saved model to disk in \",os.getcwd())\n",
    "\n",
    "#Predict known daily sales in order to check results\n",
    "predictions = model.predict(X)\n",
    "predictions_list = map(lambda x: x[0], predictions)\n",
    "predictions_series = pd.Series(predictions_list,index=dates)\n",
    "dates_series =  pd.Series(dates)\n",
    "\n",
    "#Import dates to be predicted\n",
    "df_newDates = pd.read_csv('Upcoming_dates.csv',delimiter=',',index_col='Date')\n",
    "print(\"Upcoming dates imported\")\n",
    "\n",
    "#Predict upcoming sales using trained model and imported upcoming dates\n",
    "Predicted_sales = model.predict(df_newDates)\n",
    "\n",
    "#Export predicted sales\n",
    "new_dates_series=pd.Series(df_newDates.index)\n",
    "new_predictions_list = map(lambda x: x[0], Predicted_sales)\n",
    "new_predictions_series = pd.Series(new_predictions_list,index=new_dates_series)\n",
    "new_predictions_series.to_csv(\"predicted_sales.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
